{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A test for tree models with SMOTE sampling on 2016Q1-2018Q4 datasets\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "path = 'D:\\\\2022lendingclub_ML\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet(path + '2016Q1_to_2018Q4.parquet', engine='fastparquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 已清洗好的数据（未归一化，树模型不需要归一化）。直接建模\n",
    "\n",
    "idata = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 备选模型：随机森林、XGBoost、LightGBM（快速）、Catboost；神经网络（后续补充）。先尝试未过采样的数据\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import catboost as cb\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = idata.drop(columns=['target'])\n",
    "y = idata['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随机森林，先粗设一些参数，如果出现过拟合再使用更严格剪枝策略\n",
    "\n",
    "rf0 = RandomForestClassifier(n_estimators=100, max_depth=6, random_state=0)\n",
    "y_pred_rf = rf0.fit(x_train, y_train).predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "d:\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:56:37] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "\n",
    "xgb0 = XGBClassifier(seed=0)\n",
    "y_pred_xgb = xgb0.fit(x_train, y_train).predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lightGBM\n",
    "\n",
    "lgb0 = LGBMClassifier(max_depth=6, learning_rate=0.5, n_estimators=250, random_state=0)\n",
    "y_pred_lgb = lgb0.fit(x_train, y_train).predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# catboost\n",
    "\n",
    "cb0 = cb.CatBoostClassifier(random_state=0)\n",
    "y_pred_cb = cb0.fit(x_train, y_train, verbose = 0).predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 事实证明，kaggle参赛者偏爱lightGBM不是没道理，训练速度确实很快。\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "def score_sum(y_pred, y_true):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    p = precision_score(y_true, y_pred)\n",
    "    r = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    print(f'The accuracy score is:{acc}, the precision score is:{p}, the recall score is:{r}, and the f1 score is:{f1}.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score is:0.9772706861272055, the precision score is:0.7862174940898345, the recall score is:0.9904401691583775, and the f1 score is:0.8765913703576794.\n"
     ]
    }
   ],
   "source": [
    "score_sum(y_test, y_pred_rf) # 模型过于保守，查全率太高，查准率有点低"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score is:0.9944657373312717, the precision score is:0.9541371158392435, the recall score is:0.9916461916461916, and the f1 score is:0.9725301204819278.\n"
     ]
    }
   ],
   "source": [
    "score_sum(y_test, y_pred_xgb) # 双高，性能很好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score is:0.9899994902652806, the precision score is:0.9363829787234043, the recall score is:0.9651786149422487, and the f1 score is:0.9505627684849649.\n"
     ]
    }
   ],
   "source": [
    "score_sum(y_test, y_pred_lgb) # 性能略低于xgb，但是它的训练速度真的很快"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score is:0.9944511734821435, the precision score is:0.953404255319149, the recall score is:0.9922497785651019, and the f1 score is:0.9724392361111112.\n"
     ]
    }
   ],
   "source": [
    "score_sum(y_test, y_pred_cb) # 效果基本同xgboost，问题也和xgboost一样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 针对LightGBM进行调参。只调了一部分，因为电脑性能不够。\n",
    "\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "from tune_sklearn import TuneGridSearchCV\n",
    "\n",
    "lgb_params = {\n",
    "    'max_depth' : [15, 20, 25],\n",
    "    'n_estimators' : [400, 700, 1000],\n",
    "    'num_leaves': [50, 100, 200],\n",
    "    #'reg_alpha' : [1.1, 1.2],\n",
    "    #'min_split_gain': [0.25, 0.5]\n",
    "}\n",
    "\n",
    "lgb_search = TuneGridSearchCV(\n",
    "    LGBMClassifier(),\n",
    "    lgb_params,\n",
    "    early_stopping='MedianStoppingRule',\n",
    "    max_iters=10\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-27 18:32:53,503\tWARNING tune.py:690 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      "2023-01-27 18:32:55,793\tERROR tune.py:758 -- Trials did not complete: [_Trainable_badbc_00000, _Trainable_badbc_00001, _Trainable_badbc_00002, _Trainable_badbc_00003, _Trainable_badbc_00004, _Trainable_badbc_00005, _Trainable_badbc_00006, _Trainable_badbc_00007, _Trainable_badbc_00008, _Trainable_badbc_00009, _Trainable_badbc_00010, _Trainable_badbc_00011, _Trainable_badbc_00012, _Trainable_badbc_00013, _Trainable_badbc_00014, _Trainable_badbc_00015, _Trainable_badbc_00016, _Trainable_badbc_00017, _Trainable_badbc_00018, _Trainable_badbc_00019, _Trainable_badbc_00020, _Trainable_badbc_00021, _Trainable_badbc_00022, _Trainable_badbc_00023]\n",
      "2023-01-27 18:32:55,806\tWARNING tune.py:768 -- Experiment has been interrupted, but the most recent state was saved. You can continue running this experiment by passing `resume=True` to `tune.run()`\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22420\\2371830919.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_pred_lgb_tuned\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlgb_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\Anaconda3\\lib\\site-packages\\tune_sklearn\\tune_basesearch.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, tune_params, **fit_params)\u001b[0m\n\u001b[0;32m    619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m         \"\"\"\n\u001b[1;32m--> 621\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtune_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    622\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    623\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda3\\lib\\site-packages\\tune_sklearn\\tune_basesearch.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, groups, tune_params, **fit_params)\u001b[0m\n\u001b[0;32m    533\u001b[0m                                         tune_params, fit_params)\n\u001b[0;32m    534\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 535\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv_results_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_format_results\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0manalysis_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m         \u001b[0mmetric\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_metric_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda3\\lib\\site-packages\\tune_sklearn\\tune_basesearch.py\u001b[0m in \u001b[0;36m_format_results\u001b[1;34m(self, n_splits, out)\u001b[0m\n\u001b[0;32m    856\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscoring_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 858\u001b[1;33m             _store(\n\u001b[0m\u001b[0;32m    859\u001b[0m                 \u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m                 \u001b[1;34m\"test_%s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda3\\lib\\site-packages\\tune_sklearn\\tune_basesearch.py\u001b[0m in \u001b[0;36m_store\u001b[1;34m(results, key_name, array, n_splits, n_candidates, weights, splits, rank)\u001b[0m\n\u001b[0;32m    841\u001b[0m                                             key_name)] = array[:, split_i]\n\u001b[0;32m    842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 843\u001b[1;33m             \u001b[0marray_means\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    844\u001b[0m             \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"mean_%s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mkey_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_means\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    845\u001b[0m             \u001b[1;31m# Weighted std is not directly available in numpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36maverage\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36maverage\u001b[1;34m(a, axis, weights, returned)\u001b[0m\n\u001b[0;32m    379\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mweights\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m         \u001b[0mavg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 381\u001b[1;33m         \u001b[0mscl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mavg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mavg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    382\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[0mwgt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "y_pred_lgb_tuned = lgb_search.fit(x_train, y_train).predict(x_test) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b09ec625f77bf4fd762565a912b97636504ad6ec901eb2d0f4cf5a7de23e1ee5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
